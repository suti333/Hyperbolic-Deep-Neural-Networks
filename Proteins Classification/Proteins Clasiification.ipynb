{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifolds import PoincareBall\n",
    "from utils import tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROTEINS(1113)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TUDataset(root='data/TUDataset', name='PROTEINS', transform=T.NormalizeFeatures())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sutig\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3 \n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "print(f\"Number of features: {num_features} \\nNumber of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperbolicGCNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HyperbolicGCNLayer, self).__init__(aggr='add')\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        poincare = PoincareBall(dimension=3)\n",
    "        x = poincare.mobius_matrix_vector_mul(self.weight, x)\n",
    "\n",
    "        x = self.propagate(edge_index, x=x)\n",
    "        x = poincare.mobius_add(x, self.bias)\n",
    "        return tanh(x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperbolicGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(HyperbolicGCN, self).__init__()\n",
    "        self.conv1 = HyperbolicGCNLayer(in_channels, hidden_channels)\n",
    "        self.conv2 = HyperbolicGCNLayer(hidden_channels, hidden_channels)\n",
    "        self.conv3 = HyperbolicGCNLayer(hidden_channels, hidden_channels)\n",
    "        self.global_pool = global_mean_pool\n",
    "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.global_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.7302, Train Acc: 0.5955, Val Acc: 0.5766\n",
      "Epoch 2: Loss: 0.6780, Train Acc: 0.5955, Val Acc: 0.5766\n",
      "Epoch 3: Loss: 0.6816, Train Acc: 0.5955, Val Acc: 0.5766\n",
      "Epoch 4: Loss: 0.6767, Train Acc: 0.5955, Val Acc: 0.5766\n",
      "Epoch 5: Loss: 0.6533, Train Acc: 0.6416, Val Acc: 0.7117\n",
      "Epoch 6: Loss: 0.6321, Train Acc: 0.7090, Val Acc: 0.6667\n",
      "Epoch 7: Loss: 0.6247, Train Acc: 0.6820, Val Acc: 0.7207\n",
      "Epoch 8: Loss: 0.6306, Train Acc: 0.6652, Val Acc: 0.6126\n",
      "Epoch 9: Loss: 0.6383, Train Acc: 0.7067, Val Acc: 0.7027\n",
      "Epoch 10: Loss: 0.6351, Train Acc: 0.7022, Val Acc: 0.6577\n",
      "Epoch 11: Loss: 0.6211, Train Acc: 0.7101, Val Acc: 0.6577\n",
      "Epoch 12: Loss: 0.6465, Train Acc: 0.7112, Val Acc: 0.6937\n",
      "Epoch 13: Loss: 0.6265, Train Acc: 0.6270, Val Acc: 0.6577\n",
      "Epoch 14: Loss: 0.6524, Train Acc: 0.6022, Val Acc: 0.5946\n",
      "Epoch 15: Loss: 0.6330, Train Acc: 0.6798, Val Acc: 0.7027\n",
      "Epoch 16: Loss: 0.6282, Train Acc: 0.7180, Val Acc: 0.6937\n",
      "Epoch 17: Loss: 0.6125, Train Acc: 0.7000, Val Acc: 0.7027\n",
      "Epoch 18: Loss: 0.6315, Train Acc: 0.6517, Val Acc: 0.5676\n",
      "Epoch 19: Loss: 0.6314, Train Acc: 0.7067, Val Acc: 0.6937\n",
      "Epoch 20: Loss: 0.6147, Train Acc: 0.7056, Val Acc: 0.6847\n",
      "Epoch 21: Loss: 0.6273, Train Acc: 0.6596, Val Acc: 0.7117\n",
      "Epoch 22: Loss: 0.6169, Train Acc: 0.6978, Val Acc: 0.7297\n",
      "Epoch 23: Loss: 0.6221, Train Acc: 0.6663, Val Acc: 0.6126\n",
      "Epoch 24: Loss: 0.6239, Train Acc: 0.6742, Val Acc: 0.6486\n",
      "Epoch 25: Loss: 0.6273, Train Acc: 0.6933, Val Acc: 0.6577\n",
      "Epoch 26: Loss: 0.6217, Train Acc: 0.7045, Val Acc: 0.7027\n",
      "Epoch 27: Loss: 0.6178, Train Acc: 0.6933, Val Acc: 0.7027\n",
      "Epoch 28: Loss: 0.6172, Train Acc: 0.6989, Val Acc: 0.6577\n",
      "Epoch 29: Loss: 0.6256, Train Acc: 0.6921, Val Acc: 0.6396\n",
      "Epoch 30: Loss: 0.6214, Train Acc: 0.7011, Val Acc: 0.6577\n",
      "Epoch 31: Loss: 0.6100, Train Acc: 0.6461, Val Acc: 0.6396\n",
      "Epoch 32: Loss: 0.6091, Train Acc: 0.7011, Val Acc: 0.6757\n",
      "Epoch 33: Loss: 0.6182, Train Acc: 0.6719, Val Acc: 0.6486\n",
      "Epoch 34: Loss: 0.6232, Train Acc: 0.7101, Val Acc: 0.6667\n",
      "Epoch 35: Loss: 0.6129, Train Acc: 0.6685, Val Acc: 0.6306\n",
      "Epoch 36: Loss: 0.6144, Train Acc: 0.7067, Val Acc: 0.6937\n",
      "Epoch 37: Loss: 0.6275, Train Acc: 0.6663, Val Acc: 0.6216\n",
      "Epoch 38: Loss: 0.6188, Train Acc: 0.6618, Val Acc: 0.7297\n",
      "Epoch 39: Loss: 0.6140, Train Acc: 0.6933, Val Acc: 0.7207\n",
      "Epoch 40: Loss: 0.6219, Train Acc: 0.6978, Val Acc: 0.6486\n",
      "Epoch 41: Loss: 0.6129, Train Acc: 0.7034, Val Acc: 0.6937\n",
      "Epoch 42: Loss: 0.6065, Train Acc: 0.7056, Val Acc: 0.6486\n",
      "Epoch 43: Loss: 0.6121, Train Acc: 0.7045, Val Acc: 0.6937\n",
      "Epoch 44: Loss: 0.6109, Train Acc: 0.6944, Val Acc: 0.7297\n",
      "Epoch 45: Loss: 0.6220, Train Acc: 0.6438, Val Acc: 0.6126\n",
      "Epoch 46: Loss: 0.6240, Train Acc: 0.7045, Val Acc: 0.6847\n",
      "Epoch 47: Loss: 0.6056, Train Acc: 0.7056, Val Acc: 0.7027\n",
      "Epoch 48: Loss: 0.6037, Train Acc: 0.7045, Val Acc: 0.6757\n",
      "Epoch 49: Loss: 0.6031, Train Acc: 0.6989, Val Acc: 0.6577\n",
      "Epoch 50: Loss: 0.6057, Train Acc: 0.7056, Val Acc: 0.6847\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = HyperbolicGCN(in_channels=num_features, hidden_channels=64, out_channels=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_path = 'best_hyperbolic_gcn.pth'\n",
    "for epoch in range(50):\n",
    "    loss = train()\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.46%\n"
     ]
    }
   ],
   "source": [
    "test_model = HyperbolicGCN(in_channels=num_features, hidden_channels=64, out_channels=num_classes).to(device)\n",
    "test_model.load_state_dict(torch.load(best_model_path))\n",
    "test_acc = evaluate(test_loader)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
